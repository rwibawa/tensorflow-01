{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4068e81-f607-4c12-ae78-12ea70373dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/tutorials/quickstart/beginner\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d73e2c-07f7-43a0-a29f-73f1cc584889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset\n",
    "# Load and prepare the MNIST dataset. The pixel values of the images range from 0 through 255. \n",
    "# Scale these values to a range of 0 to 1 by dividing the values by 255.0. \n",
    "# This also converts the sample data from integers to floating-point numbers:\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458907b2-b62c-49ae-8b5a-6e58622299c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a machine learning model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c74c721-2c1f-4be6-950d-eb49f3d8026c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51773024,  0.18127513,  0.40085638,  0.00839549,  0.59502363,\n",
       "        -0.30197018,  0.29418075,  0.58713317, -0.18971702, -0.81171703]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential is useful for stacking layers where each layer has one input tensor and one output tensor. \n",
    "# Layers are functions with a known mathematical structure that can be reused and have trainable variables. \n",
    "# Most TensorFlow models are composed of layers. This model uses the Flatten, Dense, and Dropout layers.\n",
    "\n",
    "# For each example, the model returns a vector of logits or log-odds scores, one for each class.\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de90af05-d034-4830-b064-069f7096a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13596414, 0.0971189 , 0.12096693, 0.0817002 , 0.14689007,\n",
       "        0.05990085, 0.10872716, 0.1457356 , 0.06701684, 0.0359793 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tf.nn.softmax function converts these logits to probabilities for each class:\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374955e6-6626-4c27-93b8-b047773fbeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function for training using losses.SparseCategoricalCrossentropy:\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b15be04-809a-48a9-9337-d3ba199cba60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8150647"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loss function takes a vector of ground truth values and a vector of logits and returns a scalar loss for each example. \n",
    "# This loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class.\n",
    "\n",
    "# This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.math.log(1/10) ~= 2.3.\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aae6740-7b17-4ae7-9322-43e98cda1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you start training, configure and compile the model using Keras Model.compile. \n",
    "# Set the optimizer class to adam, set the loss to the loss_fn function you defined earlier, \n",
    "# and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy.\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0063968-d6bc-438f-a5e5-d5642be624bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3031 - accuracy: 0.9119\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1466 - accuracy: 0.9567\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1095 - accuracy: 0.9663\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0890 - accuracy: 0.9728\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0760 - accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f877bc790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate your model\n",
    "# Use the Model.fit method to adjust your model parameters and minimize the loss:\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c8c54c9-2bac-4117-9c1b-b6881b85daea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0749 - accuracy: 0.9768 - 924ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07489185780286789, 0.9768000245094299]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Model.evaluate method checks the model's performance, usually on a validation set or test set.\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54c149a-d4e3-4546-9d17-6c21153b115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[5.60082617e-06, 1.08991216e-08, 3.28499882e-05, 2.22538525e-04,\n",
       "        3.69246821e-11, 2.59061068e-07, 1.80446554e-12, 9.99683022e-01,\n",
       "        8.05079878e-07, 5.49294418e-05],\n",
       "       [1.30892033e-07, 2.08829442e-05, 9.99931455e-01, 1.48248273e-05,\n",
       "        2.44840726e-18, 3.26104382e-05, 1.38876160e-07, 1.67643728e-14,\n",
       "        4.46330510e-08, 1.83612010e-15],\n",
       "       [6.07859590e-07, 9.99441445e-01, 2.12906198e-05, 1.00424609e-06,\n",
       "        1.76391022e-05, 1.90953938e-06, 2.32312705e-05, 3.93400493e-04,\n",
       "        9.89242690e-05, 6.06548042e-07],\n",
       "       [9.99990940e-01, 1.81564430e-10, 1.77114032e-07, 1.98709245e-08,\n",
       "        2.43709426e-08, 2.66545476e-06, 4.23389474e-06, 1.22934239e-06,\n",
       "        1.62316294e-09, 6.86229157e-07],\n",
       "       [9.19045397e-06, 5.73718983e-09, 4.64682535e-06, 1.09408404e-07,\n",
       "        9.98803973e-01, 5.00637725e-07, 1.84538258e-05, 7.05435523e-05,\n",
       "        1.62399158e-06, 1.09100842e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\n",
    "\n",
    "# If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde663ef-876f-4e00-9642-d6372d3247bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# Congratulations! You have trained a machine learning model using a prebuilt dataset using the Keras API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
